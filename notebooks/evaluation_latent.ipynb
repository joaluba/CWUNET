{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## IMPORT LIBRARIES ##################\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import importlib\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (4, 3)\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '/home/ubuntu/guestxr2/home/ubuntu/joanna/CWUNET/notebooks/../src/models.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################## IMPORT MY MODULES ##################\n",
    "sys.path.append('../src')\n",
    "\n",
    "import helpers as hlp\n",
    "import evaluation\n",
    "import dataset as ds\n",
    "import trainer\n",
    "import models\n",
    "\n",
    "importlib.reload(evaluation)\n",
    "importlib.reload(hlp)\n",
    "importlib.reload(ds)\n",
    "importlib.reload(trainer)\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## LOAD TRAINING RESULTS AND CONFIG  ##################\n",
    "\n",
    "datapath=\"/home/ubuntu/guestxr2/home/ubuntu/joanna/CWUNET/results/\"\n",
    "exp_tag=\"\"\n",
    "train_tag=\"big_1\"\n",
    "\n",
    "# load the best checkpoint from the training\n",
    "config ,train_results = trainer.load_train_results(datapath, exp_tag, train_tag,configtype=\"yaml\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## LOAD DATASET ##################\n",
    "\n",
    "# instantiate a test data set \n",
    "config[\"df_metadata\"]=\"/home/ubuntu/guestxr2/home/ubuntu/joanna/CWUNET/dataset-metadata/ds1_metadata_big.csv\"\n",
    "config[\"split\"]=\"test\"\n",
    "config[\"p_noise\"]=0\n",
    "dataset=ds.DatasetReverbTransfer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################## LOAD MODELS AND TRAINING WEIGHTS  ##################\n",
    "\n",
    "model=trainer.load_chosen_model(config,config[\"modeltype\"])\n",
    "model.load_state_dict(train_results[\"model_state_dict\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## GENERATE EMBEDDING ARRAY AND PARAMETER ARRAYS FROM MULTIPLE DATA POINTS ##################\n",
    "\n",
    "Nr_embeddings=100\n",
    "emb_arr=np.zeros([Nr_embeddings,512])\n",
    "rt30_meas_arr=np.zeros([Nr_embeddings,1])\n",
    "edt_meas_arr=np.zeros([Nr_embeddings,1])\n",
    "c50_meas_arr=np.zeros([Nr_embeddings,1])\n",
    "rt60_set_arr=np.zeros([Nr_embeddings,1])\n",
    "rt60_true_arr=np.zeros([Nr_embeddings,1])\n",
    "\n",
    "for j in range(0,Nr_embeddings):\n",
    "    data=dataset[j]\n",
    "    # get style audio\n",
    "    sStyle_in=data[1]\n",
    "    # get style info\n",
    "    df_Style=dataset.get_info(j,id=\"style\")\n",
    "    # get style embedding of size 512\n",
    "    with torch.no_grad():\n",
    "        embedding=model.conditioning_network(sStyle_in.unsqueeze(0).to(config[\"device\"]))\n",
    "        emb_arr[j,:]=embedding.cpu().numpy()\n",
    "    rt30_meas_arr[j]=df_Style[\"rt30_meas\"]\n",
    "    rt60_set_arr[j]=df_Style[\"rt60_set\"]\n",
    "    rt60_true_arr[j]=df_Style[\"rt60_true\"]\n",
    "    edt_meas_arr[j]=df_Style[\"edt_meas\"]\n",
    "    c50_meas_arr[j]=df_Style[\"c50_meas\"]\n",
    "    if j==Nr_embeddings:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save arrays with embeddings and parameters\n",
    "np.save('emb_arr3.npy', emb_arr)\n",
    "np.save('rt30_meas_arr3.npy', rt30_meas_arr)\n",
    "np.save('rt60_set_arr3.npy', rt60_set_arr)\n",
    "np.save('rt60_true_arr3.npy', rt60_true_arr)\n",
    "np.save('edt_meas_arr3.npy', edt_meas_arr)\n",
    "np.save('c50_meas_arr3.npy', c50_meas_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the saved arrays\n",
    "emb_arr = np.load('emb_arr3.npy')\n",
    "rt30_meas_arr = np.load('rt30_meas_arr3.npy')\n",
    "rt60_set_arr = np.load('rt60_set_arr3.npy')\n",
    "rt60_true_arr = np.load('rt60_true_arr3.npy')\n",
    "edt_meas_arr = np.load('edt_meas_arr3.npy')\n",
    "c50_meas_arr = np.load('c50_meas_arr3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'umap' has no attribute 'UMAP'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m embeddings_tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m, perplexity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\u001b[38;5;241m.\u001b[39mfit_transform(emb_arr[indices_subset,:])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# using u-map:\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m embeddings_umap \u001b[38;5;241m=\u001b[39m \u001b[43mumap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUMAP\u001b[49m(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mfit_transform(emb_arr[indices_subset, :])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'umap' has no attribute 'UMAP'"
     ]
    }
   ],
   "source": [
    "################## PERFORM DIMENSIONALITY REDUCTION ON THE EMBEDDING SPACE ##################\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "indices_subset=range(0,Nr_embeddings)\n",
    "# using pca:\n",
    "embeddings_pca=PCA(n_components=2).fit_transform(emb_arr[indices_subset,:])\n",
    "# using first pca and then tsne:\n",
    "embeddings_pca_tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=50).fit_transform(PCA(n_components=20).fit_transform(emb_arr[indices_subset,:]))\n",
    "# using tsne:\n",
    "embeddings_tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=50).fit_transform(emb_arr[indices_subset,:])\n",
    "# using u-map:\n",
    "embeddings_umap = umap.UMAP(n_components=2).fit_transform(emb_arr[indices_subset, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## PLOT TSNE 2-DIM VISUALISATION OF THE EMBEDDING SPACE ##################\n",
    "\n",
    "cmap = plt.get_cmap('gnuplot2')\n",
    "\n",
    "# embeddings_tsne=embeddings_tsne[0:500,:]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.suptitle('Visualization of embedding space with TSNE, perplexity=50', fontsize=16)\n",
    "plt.subplot(3,1,1)\n",
    "plt.set_cmap(cmap)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=rt60_true_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=RT60')\n",
    "plt.subplot(3,1,2)\n",
    "plt.set_cmap(cmap)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=edt_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=EDT')\n",
    "plt.subplot(3,1,3)\n",
    "plt.set_cmap(cmap)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=c50_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=C50')\n",
    "plt.set_cmap(cmap)\n",
    "plt.tight_layout()\n",
    "plt.savefig('TSNE.pdf', format='pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.suptitle('Visualization of embedding space with PCA', fontsize=16)\n",
    "plt.subplot(3,1,1)\n",
    "plt.scatter(embeddings_pca[:,0] , embeddings_pca[:,1], c=rt60_true_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=RT60')\n",
    "plt.subplot(3,1,2)\n",
    "plt.scatter(embeddings_pca[:,0] , embeddings_pca[:,1], c=edt_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=EDT')\n",
    "plt.subplot(3,1,3)\n",
    "plt.scatter(embeddings_pca[:,0] , embeddings_pca[:,1], c=c50_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=C50')\n",
    "plt.tight_layout()\n",
    "plt.savefig('PCA.pdf', format='pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.suptitle('Visualization of embedding space with UMAP', fontsize=16)\n",
    "plt.subplot(3,1,1)\n",
    "plt.scatter(embeddings_umap[:,0] , embeddings_umap[:,1], c=rt60_true_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=RT60')\n",
    "plt.subplot(3,1,2)\n",
    "plt.scatter(embeddings_umap[:,0] , embeddings_umap[:,1], c=edt_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=EDT')\n",
    "plt.subplot(3,1,3)\n",
    "plt.scatter(embeddings_umap[:,0] , embeddings_umap[:,1], c=c50_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=C50')\n",
    "plt.tight_layout()\n",
    "plt.savefig('UMAP.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## GENERATE EMBEDDING ARRAY AND PARAMETER ARRAYS FROM MULTIPLE DATA POINTS FROM THE SAME RIR ##################\n",
    "\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "\n",
    "# Create a special data set containing style data with only one specific impulse response\n",
    "N_audios=100\n",
    "N_irs=5\n",
    "emb_arr=np.zeros([N_audios*N_irs,512])\n",
    "id_array=np.zeros([N_audios*N_irs,1])\n",
    "\n",
    "\n",
    "# styleIR_indices=list(range(0, N_irs))\n",
    "\n",
    "styleIR_indices= [0,1,11,3,12]\n",
    "\n",
    "styleIR_indices=np.random.randint(10000, size=N_irs)\n",
    "\n",
    "styleIR_indices=[6786, 9377, 2068, 0, 12]\n",
    "\n",
    "for i,idx in enumerate(styleIR_indices):\n",
    "    config[\"split\"]=\"test\"\n",
    "    config[\"style_rir\"]=dataset.get_info(idx)[\"ir_file_path\"]\n",
    "    print(config[\"style_rir\"])\n",
    "    dataset_this_ir=ds.DatasetReverbTransfer(config)\n",
    "    # indices_audios=list(range(0,N_audios))\n",
    "    indices_audios=list(np.random.randint(10000, size=N_audios))\n",
    "    dataset_this_ir=Subset(dataset_this_ir,indices_audios)\n",
    "\n",
    "    for j,data in enumerate(dataset_this_ir):\n",
    "        # get style audio\n",
    "        sStyle_in=data[1]\n",
    "        # get style embedding of size 512\n",
    "        with torch.no_grad():\n",
    "            embedding=model.conditioning_network(sStyle_in.unsqueeze(0).to(config[\"device\"]))\n",
    "            emb_arr[(i*N_audios)+j,:]=embedding.cpu().numpy()\n",
    "        id_array[(i*N_audios)+j]=i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styleIR_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## PERFORM DIMENSIONALITY REDUCTION ON THE EMBEDDING SPACE ##################\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# reduce dimensionality of the embeddings\n",
    "# using pca:\n",
    "embeddings_pca_rir=PCA(n_components=2).fit_transform(emb_arr)\n",
    "# using first pca and then tsne:\n",
    "# embeddings_pca_tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=20).fit_transform(PCA(n_components=50).fit_transform(emb_arr))\n",
    "# using tsne:\n",
    "embeddings_tsne_rir = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=10).fit_transform(emb_arr)\n",
    "\n",
    "# using u-map:\n",
    "embeddings_umap_rir = umap.UMAP(n_components=2).fit_transform(emb_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=id_array.astype(str).tolist()\n",
    "\n",
    "id_array=id_array+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## PLOT TSNE 2-DIM VISUALISATION OF THE EMBEDDING SPACE ##################\n",
    "\n",
    "# Define a colormap with 5 distinct colors\n",
    "import matplotlib.colors as mcolors\n",
    "cmap = mcolors.ListedColormap(['red', 'blue', 'green', 'purple', 'orange'])\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.subplot(2,1,1)\n",
    "plt.suptitle('Visualization of embedding space with TSNE, perplexity=50', fontsize=12)\n",
    "plt.scatter(embeddings_tsne_rir[:,0] , embeddings_tsne_rir[:,1], c=id_array, cmap=cmap,alpha=0.5);plt.colorbar();plt.title('colormap=RIR ID')\n",
    "plt.subplot(2,1,2)\n",
    "plt.suptitle('Visualization of embedding space with PCA', fontsize=12)\n",
    "plt.scatter(embeddings_pca_rir[:,0] , embeddings_pca_rir[:,1], c=id_array, cmap=cmap, alpha=0.5);plt.colorbar();plt.title('colormap=RIR ID')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lat2.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a colormap with 5 distinct colors\n",
    "import matplotlib.colors as mcolors\n",
    "cmap = mcolors.ListedColormap(['red', 'blue', 'green', 'purple', 'orange'])\n",
    "\n",
    "plt.figure(figsize=(6,9))\n",
    "plt.suptitle('Visualization of embedding space with PCA', fontsize=16)\n",
    "plt.subplot(4,1,1)\n",
    "plt.scatter(embeddings_pca[:,0] , embeddings_pca[:,1], c=rt60_true_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=RT60')\n",
    "plt.subplot(4,1,2)\n",
    "plt.scatter(embeddings_pca[:,0] , embeddings_pca[:,1], c=edt_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=EDT')\n",
    "plt.subplot(4,1,3)\n",
    "plt.scatter(embeddings_pca[:,0] , embeddings_pca[:,1], c=c50_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=C50')\n",
    "plt.subplot(4,1,4)\n",
    "plt.scatter(embeddings_pca_rir[:,0] , embeddings_pca_rir[:,1], c=id_array, cmap=cmap, alpha=0.5);plt.colorbar();plt.title('colormap=RIR ID')\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca.pdf', format='pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,9))\n",
    "plt.suptitle('Visualization of embedding space with TSNE', fontsize=16)\n",
    "plt.subplot(4,1,1)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=rt60_true_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=RT60')\n",
    "plt.subplot(4,1,2)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=edt_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=EDT')\n",
    "plt.subplot(4,1,3)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=c50_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=C50')\n",
    "plt.subplot(4,1,4)\n",
    "plt.scatter(embeddings_tsne_rir[:,0] , embeddings_tsne_rir[:,1], c=id_array, cmap=cmap, alpha=0.5);plt.colorbar();plt.title('colormap=RIR ID')\n",
    "plt.tight_layout()\n",
    "plt.savefig('tsne.pdf', format='pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,9))\n",
    "plt.suptitle('Visualization of embedding space with UMAP', fontsize=16)\n",
    "plt.subplot(4,1,1)\n",
    "plt.scatter(embeddings_umap[:,0] , embeddings_umap[:,1], c=rt60_true_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=RT60')\n",
    "plt.subplot(4,1,2)\n",
    "plt.scatter(embeddings_umap[:,0] , embeddings_umap[:,1], c=edt_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=EDT')\n",
    "plt.subplot(4,1,3)\n",
    "plt.scatter(embeddings_umap[:,0] , embeddings_umap[:,1], c=c50_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=C50')\n",
    "plt.subplot(4,1,4)\n",
    "plt.scatter(embeddings_umap_rir[:,0] , embeddings_umap_rir[:,1], c=id_array, cmap=cmap, alpha=0.5);plt.colorbar();plt.title('colormap=RIR ID')\n",
    "plt.tight_layout()\n",
    "plt.savefig('umap.pdf', format='pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
