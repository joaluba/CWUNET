{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## IMPORT LIBRARIES ##################\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import sys\n",
    "import importlib\n",
    "import random \n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True\n",
    "import time\n",
    "from os.path import join as pjoin\n",
    "from acoustics.bands import third\n",
    "import scipy.signal as sig\n",
    "from IPython.display import Audio\n",
    "# from masp import shoebox_room_sim as srs\n",
    "from scipy.io import wavfile\n",
    "#import mat73\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (4, 3)\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## IMPORT MY MODULES ##################\n",
    "sys.path.append('../src')\n",
    "\n",
    "import helpers as hlp\n",
    "import evaluation\n",
    "import dataset as ds\n",
    "import trainer\n",
    "import models\n",
    "\n",
    "importlib.reload(evaluation)\n",
    "importlib.reload(hlp)\n",
    "importlib.reload(ds)\n",
    "importlib.reload(trainer)\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## LOAD TRAINING RESULTS AND CONFIG  ##################\n",
    "\n",
    "datapath=\"/home/ubuntu/Data/RESULTS-reverb-match-cond-u-net/\"\n",
    "exp_tag=\"runs-exp-20-05-2024\"\n",
    "train_tag=\"10-06-2024--15-02_c_wunet_stft+wave_0.8_0.2\"\n",
    "\n",
    "config ,train_results = trainer.load_train_results(datapath, exp_tag, train_tag,configtype=\"yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## LOAD DATASET ##################\n",
    "\n",
    "# instantiate a test data set \n",
    "config[\"split\"]=\"test\"\n",
    "config[\"df_metadata\"]=\"/home/ubuntu/joanna/reverb-match-cond-u-net/dataset-metadata/17-05-2024--15-42_data_set.csv\"\n",
    "config[\"p_noise\"]=0\n",
    "dataset=ds.DatasetReverbTransfer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## LOAD MODELS AND TRAINING WEIGHTS  ##################\n",
    "\n",
    "model=trainer.load_chosen_model(config,config[\"modeltype\"])\n",
    "model.load_state_dict(train_results[\"model_state_dict\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## SEARCH FOR DATA POINTS FROM TEST SET WITH SPECIFIC RT60 VALUES   ##################\n",
    "\n",
    "# choose indices from a data set with specified difference\n",
    "chosen_rt60_idx_list=dataset.get_idx_with_rt60diff(-2,-0.85)\n",
    "# chosen_rt60_idx_list=dataset.get_idx_with_rt60diff(0.8,2)\n",
    "len(chosen_rt60_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## INFERENCE FOR ONE DATA SAMPLE  ##################\n",
    "\n",
    "dp=chosen_rt60_idx_list[random.randint(0, len(chosen_rt60_idx_list) - 1)]\n",
    "sContent,sStyle,sTarget,sPrediction=trainer.infer(model,dataset[dp],config[\"device\"])\n",
    "if bool(config[\"is_vae\"]):\n",
    "    sPrediction, _, _ = sPrediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## GENERATE EMBEDDING ARRAY AND PARAMETER ARRAYS FROM MULTIPLE DATA POINTS ##################\n",
    "\n",
    "emb_arr=np.zeros([len(dataset),512])\n",
    "rt30_meas_arr=np.zeros([len(dataset),1])\n",
    "edt_meas_arr=np.zeros([len(dataset),1])\n",
    "c50_meas_arr=np.zeros([len(dataset),1])\n",
    "rt60_set_arr=np.zeros([len(dataset),1])\n",
    "rt60_true_arr=np.zeros([len(dataset),1])\n",
    "for j,data in enumerate(dataset):\n",
    "    # get style audio\n",
    "    sStyle_in=data[1]\n",
    "    # get style info\n",
    "    df_Style=dataset.get_info(j,id=\"style\")\n",
    "    # get style embedding of size 512\n",
    "    with torch.no_grad():\n",
    "        embedding=model.conditioning_network(sStyle_in.unsqueeze(0).to(config[\"device\"]))\n",
    "        emb_arr[j,:]=embedding.cpu().numpy()\n",
    "    rt30_meas_arr[j]=df_Style[\"rt30_meas\"]\n",
    "    rt60_set_arr[j]=df_Style[\"rt60_set\"]\n",
    "    rt60_true_arr[j]=df_Style[\"rt60_true\"]\n",
    "    edt_meas_arr[j]=df_Style[\"edt_meas\"]\n",
    "    c50_meas_arr[j]=df_Style[\"c50_meas\"]\n",
    "    if j==3000:\n",
    "        break\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('emb_arr3.npy', emb_arr)\n",
    "np.save('rt30_meas_arr3.npy', rt30_meas_arr)\n",
    "np.save('rt60_set_arr3.npy', rt60_set_arr)\n",
    "np.save('rt60_true_arr3.npy', rt60_true_arr)\n",
    "np.save('edt_meas_arr3.npy', edt_meas_arr)\n",
    "np.save('c50_meas_arr3.npy', c50_meas_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the saved arrays\n",
    "emb_arr = np.load('emb_arr3.npy')\n",
    "rt30_meas_arr = np.load('rt30_meas_arr3.npy')\n",
    "rt60_set_arr = np.load('rt60_set_arr3.npy')\n",
    "rt60_true_arr = np.load('rt60_true_arr3.npy')\n",
    "edt_meas_arr = np.load('edt_meas_arr3.npy')\n",
    "c50_meas_arr = np.load('c50_meas_arr3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## PERFORM DIMENSIONALITY REDUCTION ON THE EMBEDDING SPACE ##################\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "indices_subset=range(1000)\n",
    "# reduce dimensionality of the embeddings\n",
    "# using pca:\n",
    "embeddings_pca=PCA(n_components=2).fit_transform(emb_arr[indices_subset,:])\n",
    "# using first pca and then tsne:\n",
    "# embeddings_pca_tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=100).fit_transform(PCA(n_components=20).fit_transform(emb_arr[indices_subset,:]))\n",
    "# using tsne:\n",
    "embeddings_tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=100).fit_transform(emb_arr[indices_subset,:])\n",
    "# using u-map:\n",
    "embeddings_umap = umap.UMAP(n_components=2).fit_transform(emb_arr[indices_subset, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## PLOT TSNE 2-DIM VISUALISATION OF THE EMBEDDING SPACE ##################\n",
    "\n",
    "cmap = plt.get_cmap('gnuplot2')\n",
    "\n",
    "# embeddings_tsne=embeddings_tsne[0:500,:]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.suptitle('Visualization of embedding space with TSNE, perplexity=50', fontsize=16)\n",
    "plt.subplot(3,1,1)\n",
    "plt.set_cmap(cmap)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=rt60_true_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=RT60')\n",
    "plt.subplot(3,1,2)\n",
    "plt.set_cmap(cmap)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=edt_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=EDT')\n",
    "plt.subplot(3,1,3)\n",
    "plt.set_cmap(cmap)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=c50_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=C50')\n",
    "plt.set_cmap(cmap)\n",
    "plt.tight_layout()\n",
    "plt.savefig('TSNE.pdf', format='pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.suptitle('Visualization of embedding space with PCA', fontsize=16)\n",
    "plt.subplot(3,1,1)\n",
    "plt.scatter(embeddings_pca[:,0] , embeddings_pca[:,1], c=rt60_true_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=RT60')\n",
    "plt.subplot(3,1,2)\n",
    "plt.scatter(embeddings_pca[:,0] , embeddings_pca[:,1], c=edt_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=EDT')\n",
    "plt.subplot(3,1,3)\n",
    "plt.scatter(embeddings_pca[:,0] , embeddings_pca[:,1], c=c50_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=C50')\n",
    "plt.tight_layout()\n",
    "plt.savefig('PCA.pdf', format='pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.suptitle('Visualization of embedding space with UMAP', fontsize=16)\n",
    "plt.subplot(3,1,1)\n",
    "plt.scatter(embeddings_umap[:,0] , embeddings_umap[:,1], c=rt60_true_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=RT60')\n",
    "plt.subplot(3,1,2)\n",
    "plt.scatter(embeddings_umap[:,0] , embeddings_umap[:,1], c=edt_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=EDT')\n",
    "plt.subplot(3,1,3)\n",
    "plt.scatter(embeddings_umap[:,0] , embeddings_umap[:,1], c=c50_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=C50')\n",
    "plt.tight_layout()\n",
    "plt.savefig('UMAP.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## GENERATE EMBEDDING ARRAY AND PARAMETER ARRAYS FROM MULTIPLE DATA POINTS FROM THE SAME RIR ##################\n",
    "\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "\n",
    "# Create a special data set containing style data with only one specific impulse response\n",
    "N_audios=100\n",
    "N_irs=5\n",
    "emb_arr=np.zeros([N_audios*N_irs,512])\n",
    "id_array=np.zeros([N_audios*N_irs,1])\n",
    "\n",
    "\n",
    "# styleIR_indices=list(range(0, N_irs))\n",
    "\n",
    "styleIR_indices= [0,1,11,3,12]\n",
    "\n",
    "styleIR_indices=np.random.randint(10000, size=N_irs)\n",
    "\n",
    "styleIR_indices=[6786, 9377, 2068, 0, 12]\n",
    "\n",
    "for i,idx in enumerate(styleIR_indices):\n",
    "    config[\"split\"]=\"test\"\n",
    "    config[\"style_rir\"]=dataset.get_info(idx)[\"ir_file_path\"]\n",
    "    print(config[\"style_rir\"])\n",
    "    dataset_this_ir=ds.DatasetReverbTransfer(config)\n",
    "    # indices_audios=list(range(0,N_audios))\n",
    "    indices_audios=list(np.random.randint(10000, size=N_audios))\n",
    "    dataset_this_ir=Subset(dataset_this_ir,indices_audios)\n",
    "\n",
    "    for j,data in enumerate(dataset_this_ir):\n",
    "        # get style audio\n",
    "        sStyle_in=data[1]\n",
    "        # get style embedding of size 512\n",
    "        with torch.no_grad():\n",
    "            embedding=model.conditioning_network(sStyle_in.unsqueeze(0).to(config[\"device\"]))\n",
    "            emb_arr[(i*N_audios)+j,:]=embedding.cpu().numpy()\n",
    "        id_array[(i*N_audios)+j]=i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styleIR_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## PERFORM DIMENSIONALITY REDUCTION ON THE EMBEDDING SPACE ##################\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# reduce dimensionality of the embeddings\n",
    "# using pca:\n",
    "embeddings_pca_rir=PCA(n_components=2).fit_transform(emb_arr)\n",
    "# using first pca and then tsne:\n",
    "# embeddings_pca_tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=20).fit_transform(PCA(n_components=50).fit_transform(emb_arr))\n",
    "# using tsne:\n",
    "embeddings_tsne_rir = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=10).fit_transform(emb_arr)\n",
    "\n",
    "# using u-map:\n",
    "embeddings_umap_rir = umap.UMAP(n_components=2).fit_transform(emb_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=id_array.astype(str).tolist()\n",
    "\n",
    "id_array=id_array+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## PLOT TSNE 2-DIM VISUALISATION OF THE EMBEDDING SPACE ##################\n",
    "\n",
    "# Define a colormap with 5 distinct colors\n",
    "import matplotlib.colors as mcolors\n",
    "cmap = mcolors.ListedColormap(['red', 'blue', 'green', 'purple', 'orange'])\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.subplot(2,1,1)\n",
    "plt.suptitle('Visualization of embedding space with TSNE, perplexity=50', fontsize=12)\n",
    "plt.scatter(embeddings_tsne_rir[:,0] , embeddings_tsne_rir[:,1], c=id_array, cmap=cmap,alpha=0.5);plt.colorbar();plt.title('colormap=RIR ID')\n",
    "plt.subplot(2,1,2)\n",
    "plt.suptitle('Visualization of embedding space with PCA', fontsize=12)\n",
    "plt.scatter(embeddings_pca_rir[:,0] , embeddings_pca_rir[:,1], c=id_array, cmap=cmap, alpha=0.5);plt.colorbar();plt.title('colormap=RIR ID')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lat2.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a colormap with 5 distinct colors\n",
    "import matplotlib.colors as mcolors\n",
    "cmap = mcolors.ListedColormap(['red', 'blue', 'green', 'purple', 'orange'])\n",
    "\n",
    "plt.figure(figsize=(6,9))\n",
    "plt.suptitle('Visualization of embedding space with PCA', fontsize=16)\n",
    "plt.subplot(4,1,1)\n",
    "plt.scatter(embeddings_pca[:,0] , embeddings_pca[:,1], c=rt60_true_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=RT60')\n",
    "plt.subplot(4,1,2)\n",
    "plt.scatter(embeddings_pca[:,0] , embeddings_pca[:,1], c=edt_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=EDT')\n",
    "plt.subplot(4,1,3)\n",
    "plt.scatter(embeddings_pca[:,0] , embeddings_pca[:,1], c=c50_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=C50')\n",
    "plt.subplot(4,1,4)\n",
    "plt.scatter(embeddings_pca_rir[:,0] , embeddings_pca_rir[:,1], c=id_array, cmap=cmap, alpha=0.5);plt.colorbar();plt.title('colormap=RIR ID')\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca.pdf', format='pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,9))\n",
    "plt.suptitle('Visualization of embedding space with TSNE', fontsize=16)\n",
    "plt.subplot(4,1,1)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=rt60_true_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=RT60')\n",
    "plt.subplot(4,1,2)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=edt_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=EDT')\n",
    "plt.subplot(4,1,3)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=c50_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=C50')\n",
    "plt.subplot(4,1,4)\n",
    "plt.scatter(embeddings_tsne_rir[:,0] , embeddings_tsne_rir[:,1], c=id_array, cmap=cmap, alpha=0.5);plt.colorbar();plt.title('colormap=RIR ID')\n",
    "plt.tight_layout()\n",
    "plt.savefig('tsne.pdf', format='pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,9))\n",
    "plt.suptitle('Visualization of embedding space with UMAP', fontsize=16)\n",
    "plt.subplot(4,1,1)\n",
    "plt.scatter(embeddings_umap[:,0] , embeddings_umap[:,1], c=rt60_true_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=RT60')\n",
    "plt.subplot(4,1,2)\n",
    "plt.scatter(embeddings_umap[:,0] , embeddings_umap[:,1], c=edt_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=EDT')\n",
    "plt.subplot(4,1,3)\n",
    "plt.scatter(embeddings_umap[:,0] , embeddings_umap[:,1], c=c50_meas_arr[indices_subset], s=3);plt.colorbar();plt.title('colormap=C50')\n",
    "plt.subplot(4,1,4)\n",
    "plt.scatter(embeddings_umap_rir[:,0] , embeddings_umap_rir[:,1], c=id_array, cmap=cmap, alpha=0.5);plt.colorbar();plt.title('colormap=RIR ID')\n",
    "plt.tight_layout()\n",
    "plt.savefig('umap.pdf', format='pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wave-u-net2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
