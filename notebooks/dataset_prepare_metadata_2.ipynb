{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## IMPORT LIBRARIES ##################\n",
    "\n",
    "import numpy as np\n",
    "import random \n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## IMPORT MY MODULES ##################\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# directory where the data bases are stored\n",
    "datapath=\"/home/ubuntu/Data_guestxr2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- SPEECH POOL ------------\n",
    "\n",
    "# create df with paths to speech files\n",
    "speech_dataset_path1 =  pjoin(datapath,'VCTK','wav48_silence_trimmed')\n",
    "speech_dataset_path2 =  pjoin(datapath,'PTDB')\n",
    "speech_dataset_path3 =  pjoin(datapath,'EARS')\n",
    "\n",
    "# initialize empty list of files:\n",
    "speech_pool = []\n",
    "\n",
    "# fill the list of files with filenames from vctk data base:\n",
    "database=\"VCTK\"\n",
    "for root, dirs, files in os.walk(speech_dataset_path1):\n",
    "    for file in files:\n",
    "        if file.endswith('.flac'):\n",
    "            # decide which split based on a probability \n",
    "            speech_pool.append({'database_speech': database, 'speech_file_path': os.path.join(root, file)})\n",
    "\n",
    "# fill the list of files with filenames from ptdb data base:\n",
    "database=\"PTDB\"\n",
    "for root, dirs, files in os.walk(speech_dataset_path2):\n",
    "    for file in files:\n",
    "        # make sure the correct speech files are used (MIC directory)\n",
    "        if (\"/MIC/\" in root) & (file.endswith('.wav')):\n",
    "            # decide which split based on a probability \n",
    "            speech_pool.append({'database_speech': database, 'speech_file_path': os.path.join(root, file)})  \n",
    "\n",
    "\n",
    "# fill the list of files with filenames from ears data base:\n",
    "database=\"EARS\"\n",
    "for root, dirs, files in os.walk(speech_dataset_path3):\n",
    "    for file in files:\n",
    "        # make sure the correct speech files are used (MIC directory)\n",
    "        if file.endswith(('slow.wav','fast.wav','highpitch.wav','lowpitch.wav','regular.wav')):\n",
    "            # decide which split based on a probability \n",
    "            speech_pool.append({'database_speech': database, 'speech_file_path': os.path.join(root, file)})  \n",
    "\n",
    "\n",
    "# # shuffle order\n",
    "random.shuffle(speech_pool)\n",
    "\n",
    "# turn list to data frame \n",
    "speech_pool = pd.DataFrame(speech_pool).reset_index(drop=True)\n",
    "speech_pool.tail(200)\n",
    "print(f\"{len(speech_pool)=}\")\n",
    "\n",
    "# split speech pool into test, train and val (70/15/15)\n",
    "speech_train=speech_pool[speech_pool.index<int(0.7*len(speech_pool))].reset_index(drop=True)\n",
    "speech_test=speech_pool[(speech_pool.index>=int(0.7*len(speech_pool))) & (speech_pool.index<int(0.85*len(speech_pool)))].reset_index(drop=True)\n",
    "speech_val=speech_pool[(speech_pool.index>=int(0.85*len(speech_pool))) & (speech_pool.index<len(speech_pool))].reset_index(drop=True)\n",
    "\n",
    "print(f\"{len(speech_train)=}\")\n",
    "print(f\"{len(speech_test)=}\")\n",
    "print(f\"{len(speech_val)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- LOAD RIR PAIRS POOL ------------\n",
    "# Here we load the info about all generated rirs (\"rir_info.csv\")\n",
    "# Those rirs are arranged in pairs (see column \"pair_nr\")\n",
    "\n",
    "database=\"synth_rirs_new\"\n",
    "rir_path=pjoin(datapath,database)\n",
    "\n",
    "\n",
    "rirs_unique=pd.read_csv(pjoin(rir_path,\"rir_info.csv\"),index_col=0).reset_index(drop=True)\n",
    "rirs_unique = rirs_unique.loc[:, ~rirs_unique.columns.str.contains('^Unnamed')]\n",
    "unique_values = rirs_unique['ir_file_name'].unique()\n",
    "\n",
    "# make a column with a file path that includes current directory \n",
    "rirs_unique[\"ir_file_path\"] = rirs_unique[\"ir_file_name\"].apply(lambda x: pjoin(rir_path, x))\n",
    "if \"ir_clone_file_name\" in rirs_unique.columns: # if the database contained \"cloned\" RIRs (same room, different position)\n",
    "    rirs_unique[\"ir_clone_file_path\"] = rirs_unique[\"ir_clone_file_name\"].apply(lambda x: pjoin(rir_path, x))\n",
    "\n",
    "rirs_unique_train = rirs_unique[rirs_unique[\"pair_nr\"]<7000].reset_index(drop=True)\n",
    "rirs_unique_test = rirs_unique[(rirs_unique[\"pair_nr\"]>=7000) & (rirs_unique[\"pair_nr\"]<8500)].reset_index(drop=True)\n",
    "rirs_unique_val = rirs_unique[(rirs_unique[\"pair_nr\"]>=8500) & (rirs_unique[\"pair_nr\"]<10000)].reset_index(drop=True)\n",
    "\n",
    "print(f\"{len(rirs_unique_train)=}\")\n",
    "print(f\"{len(rirs_unique_test)=}\")\n",
    "print(f\"{len(rirs_unique_val)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- FUNCTION TO EXPAND RIR PAIRS POOL (BY FORMING NEW PAIRS) -----\n",
    "# we have a dataset of 10000 rir pairs with a predefined rt60diff \n",
    "# each rir has a \"clone\" meaning an rir from the same room but different src pos\n",
    "# so taking those into account we have 20000 pairs\n",
    "# now we use each pair twice (each rir can be applied either to style or to content)\n",
    "# with this, we end up with 40000 rir pairs \n",
    "# (each data point is a pair of style and content audio)\n",
    "\n",
    "# --------- finding pairs with rt60diff ~ N(0.5,02) --------\n",
    "# for each rir in this dataset, find a few additional pairs\n",
    "# (but the rt60 diff should be distributed according to gauss N(0.5,02))\n",
    "\n",
    "def expand_rir_pairs(rirs_pairs_in):\n",
    "    possible_pairs = []\n",
    "    mean_rt60diff=0.6\n",
    "    std_rt60diff=0.2\n",
    "    N_pairsperir=10\n",
    "    for idx, rt60 in rirs_pairs_in[\"rt60_set\"].items():\n",
    "        # Compute differences with all other rows\n",
    "        diffs = np.abs(rirs_pairs_in[\"rt60_set\"] - rt60)\n",
    "\n",
    "        # Exclude self-comparison\n",
    "        diffs[idx] = np.nan  \n",
    "\n",
    "        # Compute probabilities using a gauss N(0.5,02)\n",
    "        probabilities = np.exp(-((diffs - mean_rt60diff) ** 2) / (2 * std_rt60diff ** 2))\n",
    "\n",
    "        # Normalize to get a valid probability distribution\n",
    "        probabilities[np.isnan(probabilities)] = 0\n",
    "        probabilities /= np.nansum(probabilities)\n",
    "    \n",
    "        # Choose one row based on the computed probabilities\n",
    "        chosen_indices = np.random.choice(diffs.index, size=N_pairsperir, p=probabilities)\n",
    "\n",
    "        possible_pairs.append((idx, *chosen_indices))\n",
    "\n",
    "    # --------- creating an expanded list of pairs --------\n",
    "    rows=[]\n",
    "    for idx in range(0, len(rirs_pairs_in)):\n",
    "        # Copy rows of the pair\n",
    "        row0 = rirs_pairs_in.loc[idx].copy()\n",
    "\n",
    "        # Loop over the range of N  \n",
    "        for i in range(N_pairsperir-1):\n",
    "            # Use the indices from possible_pairs[idx] to get the corresponding rows\n",
    "            row = rirs_pairs_in.loc[possible_pairs[idx][i+1]].copy()  # i+1 because the first element is idx\n",
    "            rows.append(row0.copy())\n",
    "            rows.append(row)\n",
    "\n",
    "    rirs_pairs_out = pd.DataFrame(rows)\n",
    "    rirs_pairs_out=rirs_pairs_out.reset_index(drop=True)\n",
    "\n",
    "    # Compute absolute difference between rows\n",
    "    rt60diffs = rirs_pairs_out[\"rt60_set\"].diff().abs()\n",
    "\n",
    "    # Assign the same difference to both rows in each pair\n",
    "    rirs_pairs_out[\"rt60_diff\"] = rt60diffs  \n",
    "\n",
    "    # But a pair starts every second index, so we are only interested in those\n",
    "    rirs_pairs_out.loc[0::2, \"rt60_diff\"] =rirs_pairs_out.loc[1::2, \"rt60_diff\"].values\n",
    "    # pair number was the name of the column in the original csv from a data set \n",
    "    # it tells us from which original pair the current pair is formed, so i will leave \n",
    "    # it just in case\n",
    "\n",
    "    rirs_pairs_out = rirs_pairs_out.rename(columns={\"pair_nr\": \"gen_pair_nr\"})\n",
    "\n",
    "\n",
    "    return rirs_pairs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- EXPAND TRAIN, TEST AND VAL SET ----- \n",
    "rirs_train = expand_rir_pairs(rirs_unique_train)\n",
    "rirs_train[\"split\"] = \"train\"\n",
    "\n",
    "rirs_test = expand_rir_pairs(rirs_unique_test)\n",
    "rirs_test[\"split\"] = \"test\"\n",
    "\n",
    "rirs_val = expand_rir_pairs(rirs_unique_val)\n",
    "rirs_val[\"split\"] = \"val\"\n",
    "\n",
    "print(f\"{len(rirs_train)=}\")\n",
    "print(f\"{len(rirs_test)=}\")\n",
    "print(f\"{len(rirs_val)=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataframe containing rir pairs. The pairs are divided into test,train and split ((see column <split>))\")\n",
    "print(\"PAIR IS DEFINED BY TWO CONSECUTIVE ROWS idx & idx+1, where idx=range(0,N,2) (even rows start a pair)\")\n",
    "display(rirs_train.head(5))\n",
    "display(rirs_test.head(5))\n",
    "display(rirs_val.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of rt60 differences in the pairs\n",
    "plt.figure()\n",
    "plt.hist(rirs_train[\"rt60_diff\"],bins =20)\n",
    "plt.title(\"distribution of rt60diff in the rir pairs pool\")\n",
    "plt.show()\n",
    "\n",
    "# plot distribution of rt60 differences in the pairs\n",
    "plt.figure()\n",
    "plt.hist(rirs_train[\"rt60_set\"],bins =20)\n",
    "plt.title(\"distribution of rt60 in the rir pairs pool\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- CREATE METADATA FOR A DATASET BY COMBINING SPEECH AND RIRS --------\n",
    "\n",
    "def assign_speech_files(rir,speech):\n",
    "    num_extra_samples = len(rir) - len(speech)\n",
    "    extra_samples = speech.sample(n=num_extra_samples, replace=True, random_state=42)\n",
    "    speech_expanded = pd.concat([speech, extra_samples], ignore_index=True)\n",
    "    rirs_speech= pd.concat([rir.reset_index(drop=True), speech_expanded.reset_index(drop=True)], axis=1,ignore_index=False)\n",
    "    return rirs_speech \n",
    "\n",
    "rirs_speech_train= assign_speech_files(rirs_train,speech_train)\n",
    "rirs_speech_test= assign_speech_files(rirs_test,speech_test)\n",
    "rirs_speech_val= assign_speech_files(rirs_val,speech_val)\n",
    "\n",
    "print(f\"{len(rirs_speech_train)=}\")\n",
    "print(f\"{len(rirs_speech_test)=}\")\n",
    "print(f\"{len(rirs_speech_val)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Full dataset metadata (pairs of rirs with assigned speech). Separate for test, train and val:\")\n",
    "\n",
    "display(rirs_speech_train.head(5))\n",
    "display(rirs_speech_test.head(5))\n",
    "display(rirs_speech_val.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- SAVE FINAL DATASET METADATA --------\n",
    "\n",
    "from datetime import datetime\n",
    "date_tag = datetime.now().strftime(\"%d-%m-%Y--%H-%M\")\n",
    "\n",
    "dataset_metadata = pd.concat([rirs_speech_train, rirs_speech_test, rirs_speech_val], ignore_index=True)\n",
    "dataset_metadata = dataset_metadata.reset_index(drop=True)\n",
    "dataset_metadata[\"pair_idx\"] = dataset_metadata.index // 2  # Integer division groups every two rows\n",
    "\n",
    "# create pilot csv (less data for quick tests):\n",
    "dataset_metadata_pilot=pd.concat([rirs_speech_train[rirs_speech_train.index<int(0.01*len(rirs_speech_train))], \n",
    "                                  rirs_speech_test[rirs_speech_test.index<int(0.01*len(rirs_speech_test))], \n",
    "                                  rirs_speech_val[rirs_speech_val.index<int(0.01*len(rirs_speech_val))]], ignore_index=True)\n",
    "\n",
    "# save metadata to csv:\n",
    "dataset_metadata.to_csv(\"../dataset-metadata/\"+ date_tag + \"_data_set_t60diff.csv\")\n",
    "dataset_metadata_pilot.to_csv(\"../dataset-metadata/\"+ date_tag + \"_data_set_t60diff_pilot.csv\")\n",
    "\n",
    "dataset_metadata.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check saved database\n",
    "df = pd.read_csv(\"../dataset-metadata/ds2_metadata_example.csv\",index_col=0)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What data was exactly used in training? \n",
    "\n",
    "a) Speech pool: \n",
    "- VCTK (88328 audio files) + PTBD data bases (4718 audio files) + EARS (7276 audio files)\n",
    "- In total: 93046 audio files\n",
    "\n",
    "b) RIR pool: \n",
    "- 20 000 RIRs (10 000 pairs) from different rooms with varying source-receiver distance \n",
    "- Exact procedure is described in the script \"rir_dataset.ipynb\" (commited february 2025)\n",
    "- The difference between pairs of rirs is controlled - the absolute differerence rt60diff ~N(0.5,02)\n",
    "\n",
    "c) Style transfer data set\n",
    "- 252k (train) + 54k (train) + 54k (val) samples = 126k (train) + 27k (test) + 27k (val) pairs consisting of 2 audio files and 2 rirs each\n",
    "- To be able to create 352k samples, both speech and rirs are repeated\n",
    "- But there is a form of augmentation in training:\n",
    "- Every 2s audio sample is chosen randomly from a longer file\n",
    "- For each rir we also have a \"clone\" rir - from the same room but from a different source position, so they can be used interchangeably while training\n",
    "\n",
    "- 1 data point -> inputs: s1r1, s2r2 and ground truth: s1r2 \n",
    "- Each audio sample is 2s randomly chosen from the audio file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rt60 difference between style and content\n",
    "df[\"diff_rt60\"] =df[\"rt60_true\"].diff()\n",
    "df[\"diff_rt30\"] =df[\"rt30_meas\"].diff()\n",
    "df.loc[0::2, 'diff_rt60'] = df['diff_rt60'].shift(periods=-1)\n",
    "df.loc[0::2, 'diff_rt30'] = df['diff_rt30'].shift(periods=-1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "plt.subplot(2,3,1)\n",
    "plt.hist(df[\"volume\"], bins=20, edgecolor='black')\n",
    "plt.title(\"Volume of the room\")\n",
    "plt.subplot(2,3,2)\n",
    "plt.hist(df[\"rt60_true\"], bins=20, edgecolor='black')\n",
    "plt.title(\"RT60 set in simulation\")\n",
    "plt.subplot(2,3,3)\n",
    "plt.hist(df[\"rt30_meas\"], bins=20, edgecolor='black')\n",
    "plt.title(\"RT30 estimated\")\n",
    "plt.subplot(2,3,4)\n",
    "plt.hist(df[\"diff_rt60\"], bins=20, edgecolor='black')\n",
    "plt.title(\"RT60 difference between style and content\")\n",
    "plt.subplot(2,3,5)\n",
    "plt.hist(df[\"diff_rt30\"], bins=20, edgecolor='black')\n",
    "plt.title(\"RT30 difference between style and content\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Simulation with masp uses rt60 like this: \n",
    "# # Compute absorption coefficients for desired rt60 and room dimensions\n",
    "# abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "# # Small correction for sound absorption coefficients:\n",
    "# if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "#     abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPETITIONS OF FILES ACROSS DATA BASE\n",
    "\n",
    "print(len(df.groupby(\"speech_file_path\").size()))\n",
    "\n",
    "# How many times each file is repeated across the whole data base\n",
    "grouped_speech = df.groupby(\"speech_file_path\")\n",
    "grouped_rir = df.groupby(\"ir_file_path\")\n",
    "\n",
    "# How many times the files are repeated \n",
    "plt.figure(figsize=(8,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(grouped_speech.size(), bins=40, edgecolor='black')\n",
    "plt.xticks([1,2,3,4,5,6,7,8,9,10])\n",
    "plt.xlabel(\"Nr of times a file appears in the database\")\n",
    "plt.ylabel(\"Nr of files\")\n",
    "plt.title(\"Speech files\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(grouped_rir.size(), bins=40, edgecolor='black')\n",
    "plt.xticks(np.arange(10,55,10))\n",
    "plt.xlabel(\"Nr of times a file appears in the database\")\n",
    "plt.title(\"RIR files\")\n",
    "plt.ylabel(\"Nr of files\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN-TEST LEAKAGE \n",
    "split_counts_speech = grouped_speech['split'].nunique()\n",
    "split_counts_rir = grouped_rir['split'].nunique()\n",
    "\n",
    "# How many times the files are repeated \n",
    "plt.figure(figsize=(8,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(split_counts_speech, bins=40, edgecolor='black')\n",
    "plt.xticks([1,2,3])\n",
    "plt.xlabel(\"Nr of splits a file is used in\")\n",
    "plt.ylabel(\"Nr of files\")\n",
    "plt.title(\"Speech files\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(split_counts_rir, bins=40, edgecolor='black')\n",
    "plt.xticks([1,2,3])\n",
    "plt.xlabel(\"Nr of splits a file is used in \")\n",
    "plt.title(\"RIR files\")\n",
    "plt.ylabel(\"Nr of files\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check metadata in combination with a dataset class definition\n",
    "sys.path.append('../src')\n",
    "\n",
    "import helpers as hlp\n",
    "import dataset as ds\n",
    "from IPython.display import Audio\n",
    "\n",
    "importlib.reload(hlp)\n",
    "importlib.reload(ds)\n",
    "\n",
    "config=hlp.load_config(\"../config/basic.yaml\")\n",
    "config[\"dataset_metadata\"]=\"/home/ubuntu/joanna/CWUNET/dataset-metadata/ds2_metadata_example.csv\"\n",
    "config[\"split\"]=\"train\"\n",
    "dataset=ds.DatasetReverbTransfer(config)\n",
    "# get one data sample \n",
    "sContent, sStyle, sTarget, sAnechoContent, sAnechoStyle = dataset[2]\n",
    "\n",
    "# playback for the data sample\n",
    "audios=[sContent, sStyle, sTarget, sAnechoContent]\n",
    "names=[\"sContent\", \"sStyle\", \"sTarget\", \"sAnechoContent\"]\n",
    "\n",
    "for i,audio in enumerate(audios):\n",
    "    print(names[i])\n",
    "    audio=audio.squeeze(0).cpu()\n",
    "    display(Audio(audio,rate=48e3))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
