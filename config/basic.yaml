# ---- general arguments ----
projectdir: /home/ubuntu/guestxr2/home/ubuntu/joanna/CWUNET/
device: cuda
fs: 48000 

# ---- data and model parameters ----
sig_len: 98304 
rev_emb_len: 512 # length of the reverberation embedding
n_blocks_revenc: 14 # number of blocks in the Reverb Encoder
n_blocks_enc: 12 # number of blocks in the Encoder and Decoder of the Wave-U-Net
learnable_pooling: False # whether to use learnable pooling in the Reverb Encoder

# ---- dataset parameters ----
style_rir: null # null means it will be randomly selected (otherwise put the path to the style RIR)
content_rir: null # null means it will be randomly selected (otherwise put the path to the content RIR)
df_metadata: /home/ubuntu/guestxr2/home/ubuntu/joanna/CWUNET/dataset-metadata/ds1_metadata_big.csv
has_clones: False 
p_noise: 0 # probability of adding noise in the training set
split: train

# ---- training parameters ----
savedir: /home/ubuntu/guestxr2/home/ubuntu/joanna/CWUNET/results/ # where to store training results,
# savedir should have a unique name to later find the results (like a data and important params)
modeltype: c_wunet 
num_epochs: 300
checkpoint_step: 50
batch_size: 8
learn_rate: 0.0001
trainscheme: "separate"
losstype: stft # see loss.py for options
loss_alphas: [1]
store_outputs: 1

# arguments to resume training
resume_from_checkpoint: null # name of the checkpoint (in the savedir) to resume training from

# ----- evaluation parameters -----
eval_savedir: # can be anything, but I usually use the same as savedir (where the training results are stored)
eval_file_name: eval.csv
eval_device: cpu
batch_size_eval: 2
checkpoint_development: 0
eval_split: test
rt60diffmin: -3
rt60diffmax: 3
N_datapoints: 1000
eval_tag: 
